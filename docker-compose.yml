version: '3.8'

services:
  api:
    build: .
    container_name: rag_ai_assistant_api
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - TEMPERATURE=${TEMPERATURE:-0.0}
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-100}
      - TOP_K_RESULTS=${TOP_K_RESULTS:-3}
      - DATA_DIR=${DATA_DIR:-knowledge_data}
      - INDEX_FILE=${INDEX_FILE:-faiss_index.pkl}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./knowledge_data:/app/knowledge_data
      - ./faiss_index.pkl:/app/faiss_index.pkl
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  bot:
    build: .
    container_name: rag_ai_assistant_bot
    command: python bot.py
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - API_HOST=${API_HOST:-api}
      - API_PORT=${API_PORT:-8000}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - TEMPERATURE=${TEMPERATURE:-0.0}
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-100}
      - TOP_K_RESULTS=${TOP_K_RESULTS:-3}
      - DATA_DIR=${DATA_DIR:-knowledge_data}
      - INDEX_FILE=${INDEX_FILE:-faiss_index.pkl}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./knowledge_data:/app/knowledge_data
      - ./faiss_index.pkl:/app/faiss_index.pkl
    depends_on:
      - api
    restart: unless-stopped
